{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea0837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "from typing import List\n",
    "from utils import get_palm_mask_484, get_true_indices, sample_to_events, save_spike_data, get_filename_from_params, load_spike_data\n",
    "from itertools import product\n",
    "import os\n",
    "\n",
    "MAT_PATH = \"smarthand_dataset.mat\"\n",
    "RANK_CSV = \"res95_ranked_taxels.csv\"   # produced by your PCA+Pearson script\n",
    "SAMPLING_FREQUENCY = 100.0  # 100 frames/sec = 100 Hz\n",
    "FRAME_DURATION_MS = 1000.0 / SAMPLING_FREQUENCY  # 10 ms per frame\n",
    "NUM_FRAMES = 1200\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4519a1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(topn: int = None, num_frames: int = 50, threshold: float = 0.03, session_id: List[int] = [0, 1] , channels: bool = True, down_spike: float = 0.1, encoding: str = \"spike\", rand_pixels: int = None):\n",
    "    \"\"\"\n",
    "    Preprocess the SmartHand dataset from MATLAB file and rank taxels.\n",
    "\n",
    "    Args:\n",
    "        topn: Number of top taxels to select.\n",
    "        num_frames: Total number of frames per batch.\n",
    "        threshold: Threshold for delta modulation.\n",
    "        session_id: List of session IDs to include.\n",
    "        channels: Whether to flatten spike channels.\n",
    "        down_spike: Magnitude for down spikes.\n",
    "        encoding: Type of encoding (\"spike\", \"raw\", \"hybrid\").\n",
    "    Returns:\n",
    "        Tuple of (train_data, train_labels, test_data, test_labels)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # ==============================================================\n",
    "    # 1. Load & Normalize\n",
    "    # ==============================================================\n",
    "    data = sio.loadmat(MAT_PATH)\n",
    "    tactile = data['tactile_data'].astype(np.float32)\n",
    "    baseline = data[\"threshold\"].flatten().astype(np.float32)\n",
    "    valid = data[\"valid_flag\"].flatten().astype(bool)\n",
    "    y = data[\"object_id\"].flatten().astype(np.int64)\n",
    "    sessions = data[\"session_id\"].flatten().astype(np.int64)\n",
    "    \n",
    "    # Normalize tactile and baseline values to [0, 1]\n",
    "    tactile_norm = np.clip((tactile.astype(np.float32)-1500)/(2700-1500), 0.0, 1.0)\n",
    "    baseline_norm = np.clip((baseline-1500)/(1800-1500), 0.0, 1.0)\n",
    "\n",
    "\n",
    "    # ==============================================================\n",
    "    # 2. Filter & Taxel Selection\n",
    "    # ==============================================================\n",
    "    valid_mask = np.ones(tactile.shape[0], dtype=bool)\n",
    "    valid_mask &= valid\n",
    "    tactile_valid = tactile_norm[valid_mask]\n",
    "    y_valid = y[valid_mask]\n",
    "    sessions_valid = sessions[valid_mask]\n",
    "    palm_indices = get_true_indices(get_palm_mask_484())  # all 484 palm taxels\n",
    "    # Select hand taxels based on topn or palm mask\n",
    "    if rand_pixels is not None:\n",
    "        # Random selection from palm\n",
    "        if rand_pixels > len(palm_indices):\n",
    "            raise ValueError(f\"rand_pixels={rand_pixels} > available palm taxels ({len(palm_indices)})\")\n",
    "        rng = np.random.default_rng(seed=42)  # reproducible\n",
    "        rand_idx = rng.choice(palm_indices, size=rand_pixels, replace=False)\n",
    "        tactile_hand = tactile_valid[:, rand_idx]\n",
    "        baseline_hand = baseline_norm[rand_idx]\n",
    "        print(f\"Selected {rand_pixels} RANDOM palm taxels\")\n",
    "    elif topn is not None:\n",
    "        rank_df = pd.read_csv(RANK_CSV)\n",
    "        topn_idx = rank_df[\"Orig_idx\"].to_numpy()[:topn]\n",
    "        print(f\"Selected top-{topn} taxels: {topn_idx}\")\n",
    "        tactile_hand = tactile_valid[:, topn_idx]\n",
    "        baseline_hand = baseline_norm[topn_idx]\n",
    "    else:\n",
    "        keep_idx = np.where(palm_indices)[0]\n",
    "        tactile_hand = tactile_valid[:, keep_idx]\n",
    "        baseline_hand = baseline_norm[keep_idx]\n",
    "    \n",
    "    print(f\"Shape of tactile_hand before baseline subtraction: {tactile_hand.shape}\")  # (num_samples, num_pixels)\n",
    "    # Subtract baseline\n",
    "    tactile_hand = tactile_hand - baseline_hand\n",
    "    \n",
    "    # ==============================================================\n",
    "    # 3. Balance per (session, class)\n",
    "    # ==============================================================\n",
    "    unique_classes = np.unique(y_valid)\n",
    "    num_pixels = tactile_hand.shape[1]\n",
    "\n",
    "    frames_per_sample = NUM_FRAMES if 4 not in session_id else NUM_FRAMES - 100\n",
    "\n",
    "    tactile_balanced_list = []\n",
    "    y_balanced_list = []\n",
    "    for sess in session_id:\n",
    "        for cls in unique_classes:\n",
    "            mask = (sessions_valid == sess) & (y_valid == cls)\n",
    "            data_cls = tactile_hand[mask]\n",
    "            labels_cls = y_valid[mask]\n",
    "            # Take the first frames_per_sample frames for this class-session pair\n",
    "            n_take = min(frames_per_sample, len(data_cls))\n",
    "            tactile_balanced_list.append(data_cls[:n_take])\n",
    "            y_balanced_list.append(labels_cls[:n_take])\n",
    "\n",
    "            print(f\"Session {sess}, Class {cls}: Selected {n_take} frames\")\n",
    "\n",
    "    tactile_balanced = np.concatenate(tactile_balanced_list, axis=0)\n",
    "    y_balanced = np.concatenate(y_balanced_list, axis=0)\n",
    "\n",
    "    # Print final shapes\n",
    "    print(f\"Shape of tactile_balanced: {tactile_balanced.shape}\")  # (num_frames, num_pixels)\n",
    "    print(f\"Shape of y_balanced: {y_balanced.shape}\")  # (num_frames,)\n",
    "    \n",
    "    \n",
    "    # ==============================================================\n",
    "    # 4. Batching\n",
    "    # ==============================================================\n",
    "    b_size = num_frames\n",
    "    num_batches = len(tactile_balanced) // b_size\n",
    "    tactile_batches = tactile_balanced[:num_batches * b_size].reshape(num_batches, b_size, num_pixels)\n",
    "    y_batches = y_balanced[:num_batches * b_size:b_size]  # Take first label of each batch\n",
    "\n",
    "    # Print new batch shapes\n",
    "    print(f\"Number of batches: {num_batches}\")\n",
    "    print(f\"Shape of tactile_batches: {tactile_batches.shape}\")\n",
    "    print(f\"Shape of y_batches: {y_batches.shape}\")\n",
    "\n",
    "    # ==============================================================\n",
    "    # 5. Helper: Min-max normalization (per sample)\n",
    "    # ==============================================================\n",
    "    def min_max_norm(batch):\n",
    "        b_min, b_max = batch.min(), batch.max()\n",
    "        return np.zeros_like(batch) if b_max == b_min else (batch - b_min) / (b_max - b_min)\n",
    "\n",
    "    # ==============================================================\n",
    "    # 6. Generate Spike Tensors (only for \"spike\" and \"hybrid\")\n",
    "    # ==============================================================\n",
    "    spike_tensors_2ch = []\n",
    "    if encoding in {\"spike\", \"hybrid\"}:\n",
    "        print(\"Generating 2-channel spike tensors...\")\n",
    "        event_batches = []\n",
    "        start_time = 0.0\n",
    "        for batch in tactile_batches:\n",
    "            events = sample_to_events(batch, start_time, threshold)\n",
    "            event_batches.append(events)\n",
    "            start_time = 0.0\n",
    "\n",
    "        time_window_us = FRAME_DURATION_MS\n",
    "        max_timestamp_us = num_frames * FRAME_DURATION_MS\n",
    "        num_time_steps = int(np.ceil(max_timestamp_us / time_window_us))\n",
    "        num_channels = 2\n",
    "\n",
    "        for events in event_batches:\n",
    "            spike_tensor = np.zeros((num_time_steps, num_channels, num_pixels), dtype=np.float32)\n",
    "            if events.size > 0:\n",
    "                for x, t, p in events:\n",
    "                    time_step = min(int(t // time_window_us), num_time_steps - 1)\n",
    "                    if p > 0:\n",
    "                        spike_tensor[time_step, 0, x] = 1.0\n",
    "                    else:\n",
    "                        spike_tensor[time_step, 1, x] = down_spike\n",
    "            spike_tensors_2ch.append(spike_tensor)\n",
    "            \n",
    "    # ==============================================================\n",
    "    # 7. Final Tensor Construction by Mode\n",
    "    # ==============================================================\n",
    "    final_tensors = []\n",
    "\n",
    "    if encoding == \"spike\":\n",
    "        for spk in spike_tensors_2ch:\n",
    "            if channels == 1:\n",
    "                combined = spk[:, 0, :] + spk[:, 1, :]  # (T, F)\n",
    "            else:\n",
    "                combined = spk.reshape(num_time_steps, num_channels * num_pixels)  # (T, 2*F)\n",
    "            final_tensors.append(combined)\n",
    "\n",
    "    elif encoding == \"raw\":\n",
    "        print(\"Generating normalized raw pressure...\")\n",
    "        for batch in tactile_batches:\n",
    "            raw_centered = batch - np.mean(batch, axis=0, keepdims=True)\n",
    "            final_tensors.append(raw_centered.astype(np.float32))\n",
    "\n",
    "    elif encoding == \"hybrid\":\n",
    "        print(\"Generating hybrid: UP + DOWN + raw (3Ã— features)...\")\n",
    "        for spk, raw_batch in zip(spike_tensors_2ch, tactile_batches):\n",
    "            # UP + DOWN (flattened or not)\n",
    "            if channels == 1:\n",
    "                up_down = spk[:, 0, :] + spk[:, 1, :]  # (T, F)\n",
    "            else:\n",
    "                up_down = spk.reshape(num_time_steps, num_channels * num_pixels)  # (T, 2*F)\n",
    "\n",
    "            # Raw centered around 0 (per-pixel mean subtraction over time)\n",
    "            raw_centered = raw_batch - np.mean(raw_batch, axis=0, keepdims=True)\n",
    "\n",
    "            # Concat: [UP+DOWN, raw]\n",
    "            combined = np.concatenate([up_down, raw_centered], axis=1)  # (T, 2*F) or (T, 3*F)\n",
    "            final_tensors.append(combined.astype(np.float32))\n",
    "\n",
    "    # ==============================================================\n",
    "    # 8. Reorder by Class\n",
    "    # ==============================================================\n",
    "    unique_classes = np.unique(y_batches)\n",
    "    reordered_tensors = []\n",
    "    reordered_labels = []\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        class_idx = [i for i, lbl in enumerate(y_batches) if lbl == cls]\n",
    "        for i in class_idx:\n",
    "            reordered_tensors.append(final_tensors[i])\n",
    "            reordered_labels.append(y_batches[i])\n",
    "\n",
    "    final_tensors = reordered_tensors\n",
    "    y_tensors = np.array(reordered_labels)\n",
    "\n",
    "    print(f\"Final: {len(final_tensors)} samples\")\n",
    "    print(f\"Sample shape: {final_tensors[0].shape}\")\n",
    "    print(f\"Feature dim: {final_tensors[0].shape[1]}\")\n",
    "\n",
    "    return final_tensors, y_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f41c1fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data for params: {'topn': 64, 'num_frames': 25, 'threshold': 0.01, 'session_id': [0, 1], 'channels': 1, 'down_spike': 1.0, 'encoding': 'spike', 'rand_pixels': None}\n",
      "Selected top-64 taxels: [114  82  50 178 146  18 210 214 182 246 150 269 149 309 312 313  14 277\n",
      " 152 560 407 237 406 181 245 205 120 374 377 213 118  19 117 376 270 286\n",
      " 282 467 375 430 310 344  46 405 278 302  86 284 242 142 342  51 341 345\n",
      " 408 398 437  54 180  88 462 435 153  83]\n",
      "Shape of tactile_hand before baseline subtraction: (195072, 64)\n",
      "Session 0, Class 0: Selected 1200 frames\n",
      "Session 0, Class 1: Selected 1200 frames\n",
      "Session 0, Class 2: Selected 1200 frames\n",
      "Session 0, Class 3: Selected 1200 frames\n",
      "Session 0, Class 4: Selected 1200 frames\n",
      "Session 0, Class 5: Selected 1200 frames\n",
      "Session 0, Class 6: Selected 1200 frames\n",
      "Session 0, Class 7: Selected 1200 frames\n",
      "Session 0, Class 8: Selected 1200 frames\n",
      "Session 0, Class 9: Selected 1200 frames\n",
      "Session 0, Class 10: Selected 1200 frames\n",
      "Session 0, Class 11: Selected 1200 frames\n",
      "Session 0, Class 12: Selected 1200 frames\n",
      "Session 0, Class 13: Selected 1200 frames\n",
      "Session 0, Class 14: Selected 1200 frames\n",
      "Session 0, Class 15: Selected 1200 frames\n",
      "Session 0, Class 16: Selected 1200 frames\n",
      "Session 1, Class 0: Selected 1200 frames\n",
      "Session 1, Class 1: Selected 1200 frames\n",
      "Session 1, Class 2: Selected 1200 frames\n",
      "Session 1, Class 3: Selected 1200 frames\n",
      "Session 1, Class 4: Selected 1200 frames\n",
      "Session 1, Class 5: Selected 1200 frames\n",
      "Session 1, Class 6: Selected 1200 frames\n",
      "Session 1, Class 7: Selected 1200 frames\n",
      "Session 1, Class 8: Selected 1200 frames\n",
      "Session 1, Class 9: Selected 1200 frames\n",
      "Session 1, Class 10: Selected 1200 frames\n",
      "Session 1, Class 11: Selected 1200 frames\n",
      "Session 1, Class 12: Selected 1200 frames\n",
      "Session 1, Class 13: Selected 1200 frames\n",
      "Session 1, Class 14: Selected 1200 frames\n",
      "Session 1, Class 15: Selected 1200 frames\n",
      "Session 1, Class 16: Selected 1200 frames\n",
      "Shape of tactile_balanced: (40800, 64)\n",
      "Shape of y_balanced: (40800,)\n",
      "Number of batches: 1632\n",
      "Shape of tactile_batches: (1632, 25, 64)\n",
      "Shape of y_batches: (1632,)\n",
      "Generating 2-channel spike tensors...\n",
      "Final: 1632 samples\n",
      "Sample shape: (25, 64)\n",
      "Feature dim: 64\n",
      "Saved data to preprocessed_data/spike_data_topn_64_num_frames_25_threshold_0.01_channels_1_down_spike_1.0_encoding_spike_rand_pixels_None_session_id_0_1.pkl and metadata to preprocessed_data/spike_data_topn_64_num_frames_25_threshold_0.01_channels_1_down_spike_1.0_encoding_spike_rand_pixels_None_session_id_0_1_meta.json\n",
      "Generating data for params: {'topn': 32, 'num_frames': 25, 'threshold': 0.01, 'session_id': [0, 1], 'channels': 1, 'down_spike': 1.0, 'encoding': 'spike', 'rand_pixels': None}\n",
      "Selected top-32 taxels: [114  82  50 178 146  18 210 214 182 246 150 269 149 309 312 313  14 277\n",
      " 152 560 407 237 406 181 245 205 120 374 377 213 118  19]\n",
      "Shape of tactile_hand before baseline subtraction: (195072, 32)\n",
      "Session 0, Class 0: Selected 1200 frames\n",
      "Session 0, Class 1: Selected 1200 frames\n",
      "Session 0, Class 2: Selected 1200 frames\n",
      "Session 0, Class 3: Selected 1200 frames\n",
      "Session 0, Class 4: Selected 1200 frames\n",
      "Session 0, Class 5: Selected 1200 frames\n",
      "Session 0, Class 6: Selected 1200 frames\n",
      "Session 0, Class 7: Selected 1200 frames\n",
      "Session 0, Class 8: Selected 1200 frames\n",
      "Session 0, Class 9: Selected 1200 frames\n",
      "Session 0, Class 10: Selected 1200 frames\n",
      "Session 0, Class 11: Selected 1200 frames\n",
      "Session 0, Class 12: Selected 1200 frames\n",
      "Session 0, Class 13: Selected 1200 frames\n",
      "Session 0, Class 14: Selected 1200 frames\n",
      "Session 0, Class 15: Selected 1200 frames\n",
      "Session 0, Class 16: Selected 1200 frames\n",
      "Session 1, Class 0: Selected 1200 frames\n",
      "Session 1, Class 1: Selected 1200 frames\n",
      "Session 1, Class 2: Selected 1200 frames\n",
      "Session 1, Class 3: Selected 1200 frames\n",
      "Session 1, Class 4: Selected 1200 frames\n",
      "Session 1, Class 5: Selected 1200 frames\n",
      "Session 1, Class 6: Selected 1200 frames\n",
      "Session 1, Class 7: Selected 1200 frames\n",
      "Session 1, Class 8: Selected 1200 frames\n",
      "Session 1, Class 9: Selected 1200 frames\n",
      "Session 1, Class 10: Selected 1200 frames\n",
      "Session 1, Class 11: Selected 1200 frames\n",
      "Session 1, Class 12: Selected 1200 frames\n",
      "Session 1, Class 13: Selected 1200 frames\n",
      "Session 1, Class 14: Selected 1200 frames\n",
      "Session 1, Class 15: Selected 1200 frames\n",
      "Session 1, Class 16: Selected 1200 frames\n",
      "Shape of tactile_balanced: (40800, 32)\n",
      "Shape of y_balanced: (40800,)\n",
      "Number of batches: 1632\n",
      "Shape of tactile_batches: (1632, 25, 32)\n",
      "Shape of y_batches: (1632,)\n",
      "Generating 2-channel spike tensors...\n",
      "Final: 1632 samples\n",
      "Sample shape: (25, 32)\n",
      "Feature dim: 32\n",
      "Saved data to preprocessed_data/spike_data_topn_32_num_frames_25_threshold_0.01_channels_1_down_spike_1.0_encoding_spike_rand_pixels_None_session_id_0_1.pkl and metadata to preprocessed_data/spike_data_topn_32_num_frames_25_threshold_0.01_channels_1_down_spike_1.0_encoding_spike_rand_pixels_None_session_id_0_1_meta.json\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"topn\": [64, 32],  # Include multiple topn values for iteration\n",
    "    \"num_frames\": [25],\n",
    "    \"threshold\": [0.01],\n",
    "    \"session_id\": [[0, 1]],\n",
    "    \"channels\": [1],\n",
    "    \"down_spike\": [1.0],\n",
    "    \"encoding\": [\"spike\"],\n",
    "    \"rand_pixels\": [None],\n",
    "}\n",
    "\n",
    "output_dir = \"preprocessed_data\"\n",
    "for params in product(*param_grid.values()):\n",
    "    params_dict = dict(zip(param_grid.keys(), params))\n",
    "    print(f\"Generating data for params: {params_dict}\")\n",
    "    \n",
    "    \n",
    "    filename = get_filename_from_params(params_dict, output_dir)\n",
    "    if os.path.exists(filename):\n",
    "        print(f\"Data already exists for params {params_dict}: {filename}. Skipping generation.\")\n",
    "        continue\n",
    "    \n",
    "   \n",
    "    # Instantiate dataset\n",
    "    spike_tensors, y_tensors = preprocess_data(**params_dict)\n",
    "    \n",
    "    # Prepare parameters for saving\n",
    "    save_params = {\n",
    "        \"topn\": params_dict[\"topn\"],\n",
    "        \"num_frames\": params_dict[\"num_frames\"],\n",
    "        \"threshold\": params_dict[\"threshold\"],\n",
    "        \"session_id\": params_dict[\"session_id\"],\n",
    "        \"channels\": params_dict[\"channels\"],\n",
    "        \"down_spike\": params_dict[\"down_spike\"],\n",
    "        \"encoding\": params_dict[\"encoding\"],\n",
    "        \"rand_pixels\": params_dict[\"rand_pixels\"],\n",
    "    }\n",
    "    \n",
    "    # Save data\n",
    "    save_spike_data(\n",
    "        spike_tensors=spike_tensors,\n",
    "        y=y_tensors,\n",
    "        output_dir=output_dir,\n",
    "        params=save_params\n",
    "    )\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
